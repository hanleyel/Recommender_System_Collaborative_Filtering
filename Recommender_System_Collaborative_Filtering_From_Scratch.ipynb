{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "import sklearn\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import normalize\n",
    "import csv\n",
    "from sparsesvd import sparsesvd\n",
    "import math\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unzip_json(filename):\n",
    "    \n",
    "    print('Unzipping json file...')\n",
    "    \n",
    "    unzipped_data = pd.read_json(gzip.open(filename))\n",
    "    \n",
    "    return unzipped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output json training data as a Pandas dataframe.\n",
    "def json_to_df(file_name):\n",
    "\n",
    "    print('Converting json file to dataframe...')\n",
    "\n",
    "    try:\n",
    "        training_data = pd.read_json(file_name, lines=True)\n",
    "        return training_data\n",
    "    except:\n",
    "        print('Please try another file name.')\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_csv(dataframe, desired_filename):\n",
    "\n",
    "    print('Converting dataframe to csv: ' + desired_filename + '...')\n",
    "\n",
    "    try:\n",
    "        return dataframe.to_csv(desired_filename, index=False)\n",
    "    except:\n",
    "        print('Please try another dataframe or file name.')\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns dictionaries with unique users and products as keys and unique ints as values.\n",
    "def create_user_product_dicts(filename):\n",
    "\n",
    "    print('Creating dictionaries from CSV for unique users and products...')\n",
    "\n",
    "    user_dict = {}\n",
    "    product_dict = {}\n",
    "    user_count = 0\n",
    "    product_count = 0\n",
    "\n",
    "    with open(filename, 'r') as train_file:\n",
    "        file_reader=csv.reader(train_file, delimiter=',')\n",
    "        next(file_reader, None)\n",
    "\n",
    "        for row in file_reader:\n",
    "            if row[0] not in user_dict:\n",
    "                user_dict[row[0]] = user_count\n",
    "                user_count += 1\n",
    "            if row[1] not in product_dict:\n",
    "                product_dict[row[1]] = product_count\n",
    "                product_count += 1\n",
    "\n",
    "    return user_dict, product_dict, user_count, product_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dictionaries from CSV for unique users and products...\n"
     ]
    }
   ],
   "source": [
    "user_dict, product_dict, user_count, product_count = create_user_product_dicts('reviews.test.shortened.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training_mtx(filename, user_dict, product_dict):\n",
    "\n",
    "        print('Creating a dense matrix from training data...')\n",
    "\n",
    "        num_user_ids = len(user_dict)\n",
    "        num_product_ids = len(product_dict)\n",
    "\n",
    "        dense_matrix = np.zeros(shape=(num_user_ids, num_product_ids), dtype=np.float32)\n",
    "\n",
    "        with open(filename, 'r') as train_file:\n",
    "            matrix_reader = csv.reader(train_file, delimiter=',')\n",
    "            next(matrix_reader, None)\n",
    "            for row in matrix_reader:\n",
    "                dense_matrix[user_dict[row[0]], product_dict[row[1]]] = float(row[2])\n",
    "\n",
    "        return dense_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a dense matrix from training data...\n"
     ]
    }
   ],
   "source": [
    "training_matrix = training_mtx('reviews.test.shortened.csv', user_dict, product_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 2., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 5., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 2., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 5., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(969, 944)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Outputs dictionaries with unique test users and test products.\n",
    "def get_test_users_products(filename, training_user_dict, training_product_dict):\n",
    "\n",
    "    print('Importing test users and products...')\n",
    "\n",
    "    test_user_count = len(training_user_dict)\n",
    "    test_product_count = len(training_product_dict)\n",
    "    test_user_dict = training_user_dict.copy()\n",
    "    test_product_dict = training_product_dict.copy()\n",
    "\n",
    "    with open(filename, 'r') as test_file:\n",
    "        test_reader = csv.reader(test_file, delimiter=',')\n",
    "        next(test_reader, None)\n",
    "\n",
    "        for row in test_reader:\n",
    "            # Add unique users to test_user dictionary.\n",
    "            # print(row[1])\n",
    "            if row[1] not in test_user_dict:\n",
    "                test_user_dict[row[1]] = test_user_count\n",
    "                test_user_count += 1\n",
    "            # Add unique products to test_product dictionary.\n",
    "            # print(row[2])\n",
    "            if row[2] not in test_product_dict:\n",
    "                test_product_dict[row[2]] = test_product_count\n",
    "                test_product_count += 1\n",
    "\n",
    "    return test_user_dict, test_product_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing test users and products...\n"
     ]
    }
   ],
   "source": [
    "test_user_dict, test_product_dict = get_test_users_products('reviews.test.unlabeled.shortened.csv', user_dict, product_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(test_user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Merging new users OR new products into the matrix along the x axis\n",
    "# def merged_mtx(test_file, train_file, test_y_axis, test_x_axis, train_y_axis,\n",
    "#                train_x_axis, test_y_axis_row_num, test_x_axis_row_num, train_y_axis_row_num, train_x_axis_row_num):\n",
    "\n",
    "#     print('Merging training and test data for ratings imputation...')\n",
    "\n",
    "#     num_user_ids = len(user_dict) # Training users only\n",
    "#     num_product_ids = len(test_x_axis) # Training and test products\n",
    "\n",
    "#     merged_matrix = np.zeros(shape=(num_user_ids, num_product_ids), dtype=np.float32)\n",
    "    \n",
    "#     print('Merged matrix shape: ')\n",
    "#     print(merged_matrix.shape)\n",
    "\n",
    "#     with open(test_file, 'r') as test_file:\n",
    "#         file_reader=csv.reader(test_file, delimiter=',')\n",
    "#         next(file_reader, None)\n",
    "\n",
    "#         for row in file_reader:\n",
    "            \n",
    "#             # print(row[1])\n",
    "#             # print(test_product_dict[row[2]])\n",
    "            \n",
    "#             merged_matrix[:, test_x_axis[row[test_x_axis_row_num]]] = float(0)\n",
    "\n",
    "#     with open(train_file, 'r') as train_file:\n",
    "#         file_reader=csv.reader(train_file, delimiter=',')\n",
    "#         next(file_reader, None)\n",
    "\n",
    "#         for row in file_reader:\n",
    "#             merged_matrix[train_y_axis[row[train_y_axis_row_num]], train_x_axis[row[train_x_axis_row_num]]] = float(row[2])\n",
    "\n",
    "#     return merged_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the matrix to add extra products along the x axis\n",
    "\n",
    "def merged_mtx_products(filename, user_dict, test_product_dict):\n",
    "    \n",
    "        print('Creating a matrix with new products on the x axis...')\n",
    "\n",
    "        num_user_ids = len(user_dict)\n",
    "        num_product_ids = len(test_product_dict)\n",
    "\n",
    "        dense_matrix = np.zeros(shape=(num_user_ids, num_product_ids), dtype=np.float32)\n",
    "\n",
    "        with open(filename, 'r') as train_file:\n",
    "            matrix_reader = csv.reader(train_file, delimiter=',')\n",
    "            next(matrix_reader, None)\n",
    "            for row in matrix_reader:\n",
    "                dense_matrix[user_dict[row[0]], product_dict[row[1]]] = float(row[2])\n",
    "\n",
    "        return dense_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a matrix with new products on the x axis...\n"
     ]
    }
   ],
   "source": [
    "merged_matrix_product_rows = merged_mtx_products('reviews.test.shortened.csv', user_dict, test_product_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(969, 1040)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_matrix_product_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 2., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 5., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_matrix_product_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(merged_matrix_product_rows[-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merged_mtx_users(filename, product_dict, test_user_dict):\n",
    "\n",
    "        print('Creating a matrix with new users on the x axis...')\n",
    "\n",
    "        num_product_ids = len(product_dict)\n",
    "        num_user_ids = len(test_user_dict)\n",
    "\n",
    "        dense_matrix = np.zeros(shape=(num_product_ids, num_user_ids), dtype=np.float32)\n",
    "\n",
    "        with open(filename, 'r') as train_file:\n",
    "            matrix_reader = csv.reader(train_file, delimiter=',')\n",
    "            next(matrix_reader, None)\n",
    "            for row in matrix_reader:\n",
    "                dense_matrix[product_dict[row[1]], user_dict[row[0]]] = float(row[2])\n",
    "\n",
    "        return dense_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a matrix with new users on the x axis...\n"
     ]
    }
   ],
   "source": [
    "merged_matrix_user_rows = merged_mtx_users('reviews.test.shortened.csv', product_dict, test_user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(944, 1065)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_matrix_user_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 2., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 5., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_matrix_user_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sparse(matrix):\n",
    "    sparse_matrix = scipy.sparse.csr_matrix(merged_matrix_product_rows)\n",
    "    return sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_merged_matrix_pr = to_sparse(merged_matrix_product_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sparse_merged_matrix_ur = to_sparse(merged_matrix_user_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_merged_matrix(sparse_matrix):\n",
    "\n",
    "    print('Calculating global mean...')\n",
    "    global_mean = sparse_matrix.sum()/(sparse_matrix != 0).sum()\n",
    "    print(global_mean)\n",
    "    \n",
    "    print('Calculating row mean...')\n",
    "    matrix_row_mean = sparse_matrix.sum(1)/(sparse_matrix != 0).sum(1)\n",
    "    # print(matrix_row_mean)\n",
    "\n",
    "    print('Normalizing the data...')\n",
    "    normalized_matrix = sparse_matrix - matrix_row_mean.reshape(-1, 1)\n",
    "    \n",
    "    print('Normalized matrix: ')\n",
    "    print(normalized_matrix.shape)\n",
    "    print(normalized_matrix)\n",
    "\n",
    "    return normalized_matrix, matrix_row_mean, global_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating global mean...\n",
      "4.128\n",
      "Calculating row mean...\n",
      "Normalizing the data...\n",
      "Normalized matrix: \n",
      "(969, 1040)\n",
      "[[ 0. -5. -5. ... -5. -5. -5.]\n",
      " [-2.  0. -2. ... -2. -2. -2.]\n",
      " [-5. -5.  0. ... -5. -5. -5.]\n",
      " ...\n",
      " [-5. -5. -5. ... -5. -5. -5.]\n",
      " [-2. -2. -2. ... -2. -2. -2.]\n",
      " [-5. -5. -5. ... -5. -5. -5.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "normalized_matrix_products, matrix_row_mean_products, global_mean_products = normalize_merged_matrix(sparse_merged_matrix_pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating global mean...\n",
      "4.128\n",
      "Calculating row mean...\n",
      "Normalizing the data...\n",
      "Normalized matrix: \n",
      "(969, 1040)\n",
      "[[ 0. -5. -5. ... -5. -5. -5.]\n",
      " [-2.  0. -2. ... -2. -2. -2.]\n",
      " [-5. -5.  0. ... -5. -5. -5.]\n",
      " ...\n",
      " [-5. -5. -5. ... -5. -5. -5.]\n",
      " [-2. -2. -2. ... -2. -2. -2.]\n",
      " [-5. -5. -5. ... -5. -5. -5.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "normalized_matrix_users, matrix_row_mean_users, global_mean_users = normalize_merged_matrix(sparse_merged_matrix_ur)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_svd_from_demeaned(urm_demeaned):\n",
    "\n",
    "    print('Computing svd from de-meaned matrix...')\n",
    "\n",
    "    U, sigma, Vt = svds(urm_demeaned, k = 100)\n",
    "    S = np.diag(sigma)\n",
    "\n",
    "    return U, S, Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing svd from de-meaned matrix...\n"
     ]
    }
   ],
   "source": [
    "U_products, S_products, Vt_products = compute_svd_from_demeaned(normalized_matrix_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing svd from de-meaned matrix...\n"
     ]
    }
   ],
   "source": [
    "U_users, S_users, Vt_users = compute_svd_from_demeaned(normalized_matrix_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(969, 1040)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_matrix_products.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.24445586, -4.99878483, -4.92037002, ..., -4.99998847,\n",
       "        -4.99998847, -4.99998847],\n",
       "       [-1.99701946, -1.99956519, -1.99701946, ..., -2.00002854,\n",
       "        -2.00002854, -2.00002854],\n",
       "       [-4.92037002, -4.99878483, -4.63998896, ..., -4.99998847,\n",
       "        -4.99998847, -4.99998847],\n",
       "       ...,\n",
       "       [-5.0318666 , -4.99878483, -5.02709448, ..., -4.99998847,\n",
       "        -4.99998847, -4.99998847],\n",
       "       [-1.99701946, -1.99956519, -1.99701946, ..., -2.00002854,\n",
       "        -2.00002854, -2.00002854],\n",
       "       [-5.06782099, -4.99878483, -5.02507599, ..., -4.99998847,\n",
       "        -4.99998847, -4.99998847]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.dot(U_products, S_products), Vt_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vt_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(969, 1040)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_matrix_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.30122229, -4.99878483, -5.09301256, ..., -4.99998847,\n",
       "        -4.99998847, -4.99998847],\n",
       "       [-1.99701946, -1.99956519, -1.99701946, ..., -2.00002854,\n",
       "        -2.00002854, -2.00002854],\n",
       "       [-5.09301256, -4.99878483, -4.45486786, ..., -4.99998847,\n",
       "        -4.99998847, -4.99998847],\n",
       "       ...,\n",
       "       [-5.05644411, -4.99878483, -4.99258145, ..., -4.99998847,\n",
       "        -4.99998847, -4.99998847],\n",
       "       [-1.99701946, -1.99956519, -1.99701946, ..., -2.00002854,\n",
       "        -2.00002854, -2.00002854],\n",
       "       [-4.99515639, -4.99878483, -5.02676742, ..., -4.99998847,\n",
       "        -4.99998847, -4.99998847]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.dot(U_users, S_users), Vt_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# U_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# S_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vt_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reconstruct_demeaned_matrix(test_file, prediction_file, test_user_dict, test_product_dict,\n",
    "                                U_products, S_products, Vt_products, U_users, S_users, Vt_users,\n",
    "                                matrix_row_mean_products, matrix_row_mean_users, global_mean_products, global_mean_users):\n",
    "\n",
    "    print('Reconstructing matrix and making predictions...')\n",
    "    \n",
    "#     print(len(test_user_dict))\n",
    "#     print(len(test_product_dict))\n",
    "    \n",
    "    right_term_products = np.dot(S_products, Vt_products)\n",
    "    right_term_users = np.dot(S_users, Vt_users)\n",
    "\n",
    "    with open(test_file, 'r') as test_file:\n",
    "        test_reader = csv.reader(test_file, delimiter=',')\n",
    "        next(test_reader, None)\n",
    "        with open(prediction_file, 'w') as outfile:\n",
    "            outfile_reader = csv.writer(outfile, delimiter=',')\n",
    "            outfile_reader.writerow(['datapointID', 'overall'])\n",
    "\n",
    "            for row in test_reader:\n",
    "\n",
    "                try: \n",
    "                    # Query by user.\n",
    "                    user_query = np.dot(right_term_products.T, U_products[test_user_dict[row[0]], :].T)\n",
    "                    prediction = -user_query[test_product_dict[row[1]]]\n",
    "                    outfile_reader.writerow([row[0], prediction])\n",
    "#                     print('Query by USER')\n",
    "#                     print(row[1])\n",
    "#                     print(prediction)\n",
    "                except:\n",
    "                    try:\n",
    "                        # Query by product.\n",
    "                        product_query = np.dot(right_term_users.T, U_users[test_product_dict[row[1]], :].T)\n",
    "                        prediction = -product_query[test_user_dict[row[0]]]\n",
    "                        outfile_reader.writerow([row[0], prediction])\n",
    "#                         print('Query by PRODUCT')\n",
    "#                         print(row[1])\n",
    "#                         print(prediction)\n",
    "                    except:\n",
    "                        # If no matching users or products are found, make prediction based on global mean.\n",
    "                        prediction = ((global_mean_products + global_mean_users)/2)\n",
    "                        outfile_reader.writerow([row[0], prediction])\n",
    "#                         print('No matching query: GLOBAL MEAN')\n",
    "#                         print(row[1])\n",
    "#                         print(prediction)\n",
    "\n",
    "    print('Done.')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructing matrix and making predictions...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "predicted_ratings = reconstruct_demeaned_matrix('reviews.test.unlabeled.csv', 'reviews.test.labeled.csv',\n",
    "                                                test_user_dict, test_product_dict,\n",
    "                                                U_products, S_products, Vt_products, U_users, S_users, Vt_users, \n",
    "                                                matrix_row_mean_products, matrix_row_mean_users,\n",
    "                                                global_mean_products, global_mean_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
