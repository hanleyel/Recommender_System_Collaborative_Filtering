{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import normalize\n",
    "import csv\n",
    "from sparsesvd import sparsesvd\n",
    "import math\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unzip_json(filename):\n",
    "    \n",
    "    print('Unzipping json file...')\n",
    "    \n",
    "    unzipped_data = pd.read_json(gzip.open(filename))\n",
    "    \n",
    "    return unzipped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output json training data as a Pandas dataframe.\n",
    "def json_to_df(file_name):\n",
    "\n",
    "    print('Converting json file to dataframe...')\n",
    "\n",
    "    try:\n",
    "        training_data = pd.read_json(file_name, lines=True)\n",
    "        return training_data\n",
    "    except:\n",
    "        print('Please try another file name.')\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_csv(dataframe, desired_filename):\n",
    "\n",
    "    print('Converting dataframe to csv: ' + desired_filename + '...')\n",
    "\n",
    "    try:\n",
    "        return dataframe.to_csv(desired_filename, index=False)\n",
    "    except:\n",
    "        print('Please try another dataframe or file name.')\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns dictionaries with unique users and products as keys and unique ints as values.\n",
    "def create_user_product_dicts(filename):\n",
    "\n",
    "    print('Creating dictionaries from CSV for unique users and products...')\n",
    "\n",
    "    user_dict = {}\n",
    "    product_dict = {}\n",
    "    user_count = 0\n",
    "    product_count = 0\n",
    "\n",
    "    with open(filename, 'r') as train_file:\n",
    "        file_reader=csv.reader(train_file, delimiter=',')\n",
    "        next(file_reader, None)\n",
    "\n",
    "        for row in file_reader:\n",
    "            if row[0] not in user_dict:\n",
    "                user_dict[row[0]] = user_count\n",
    "                user_count += 1\n",
    "            if row[1] not in product_dict:\n",
    "                product_dict[row[1]] = product_count\n",
    "                product_count += 1\n",
    "\n",
    "    return user_dict, product_dict, user_count, product_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dictionaries from CSV for unique users and products...\n"
     ]
    }
   ],
   "source": [
    "user_dict, product_dict, user_count, product_count = create_user_product_dicts('reviews.training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training_mtx(filename, user_dict, product_dict):\n",
    "\n",
    "        print('Creating a dense matrix from training data...')\n",
    "\n",
    "        num_user_ids = len(user_dict)\n",
    "        num_product_ids = len(product_dict)\n",
    "\n",
    "        dense_matrix = np.zeros(shape=(num_user_ids, num_product_ids), dtype=np.float32)\n",
    "\n",
    "        with open(filename, 'r') as train_file:\n",
    "            matrix_reader = csv.reader(train_file, delimiter=',')\n",
    "            next(matrix_reader, None)\n",
    "            for row in matrix_reader:\n",
    "                dense_matrix[user_dict[row[0]], product_dict[row[1]]] = float(row[2])\n",
    "\n",
    "        return dense_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a dense matrix from training data...\n"
     ]
    }
   ],
   "source": [
    "training_matrix = training_mtx('reviews.training.csv', user_dict, product_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 5., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 5., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123952, 50050)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Outputs dictionaries with unique test users and test products.\n",
    "def get_test_users_products(filename, training_user_dict, training_product_dict):\n",
    "\n",
    "    print('Importing test users and products...')\n",
    "\n",
    "    test_user_count = len(training_user_dict)\n",
    "    test_product_count = len(training_product_dict)\n",
    "    test_user_dict = training_user_dict.copy()\n",
    "    test_product_dict = training_product_dict.copy()\n",
    "\n",
    "    with open(filename, 'r') as test_file:\n",
    "        test_reader = csv.reader(test_file, delimiter=',')\n",
    "        next(test_reader, None)\n",
    "\n",
    "        for row in test_reader:\n",
    "            # Add unique users to test_user dictionary.\n",
    "            # print(row[1])\n",
    "            if row[1] not in test_user_dict:\n",
    "                test_user_dict[row[1]] = test_user_count\n",
    "                test_user_count += 1\n",
    "            # Add unique products to test_product dictionary.\n",
    "            # print(row[2])\n",
    "            if row[2] not in test_product_dict:\n",
    "                test_product_dict[row[2]] = test_product_count\n",
    "                test_product_count += 1\n",
    "\n",
    "    return test_user_dict, test_product_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing test users and products...\n"
     ]
    }
   ],
   "source": [
    "test_user_dict, test_product_dict = get_test_users_products('reviews.test.unlabeled.csv', user_dict, product_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(test_user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Merging new users OR new products into the matrix along the x axis\n",
    "# def merged_mtx(test_file, train_file, test_y_axis, test_x_axis, train_y_axis,\n",
    "#                train_x_axis, test_y_axis_row_num, test_x_axis_row_num, train_y_axis_row_num, train_x_axis_row_num):\n",
    "\n",
    "#     print('Merging training and test data for ratings imputation...')\n",
    "\n",
    "#     num_user_ids = len(user_dict) # Training users only\n",
    "#     num_product_ids = len(test_x_axis) # Training and test products\n",
    "\n",
    "#     merged_matrix = np.zeros(shape=(num_user_ids, num_product_ids), dtype=np.float32)\n",
    "    \n",
    "#     print('Merged matrix shape: ')\n",
    "#     print(merged_matrix.shape)\n",
    "\n",
    "#     with open(test_file, 'r') as test_file:\n",
    "#         file_reader=csv.reader(test_file, delimiter=',')\n",
    "#         next(file_reader, None)\n",
    "\n",
    "#         for row in file_reader:\n",
    "            \n",
    "#             # print(row[1])\n",
    "#             # print(test_product_dict[row[2]])\n",
    "            \n",
    "#             merged_matrix[:, test_x_axis[row[test_x_axis_row_num]]] = float(0)\n",
    "\n",
    "#     with open(train_file, 'r') as train_file:\n",
    "#         file_reader=csv.reader(train_file, delimiter=',')\n",
    "#         next(file_reader, None)\n",
    "\n",
    "#         for row in file_reader:\n",
    "#             merged_matrix[train_y_axis[row[train_y_axis_row_num]], train_x_axis[row[train_x_axis_row_num]]] = float(row[2])\n",
    "\n",
    "#     return merged_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the matrix to add extra products along the x axis\n",
    "\n",
    "def merged_mtx_products(filename, user_dict, test_product_dict):\n",
    "    \n",
    "        print('Creating a matrix with new products on the x axis...')\n",
    "\n",
    "        num_user_ids = len(user_dict)\n",
    "        num_product_ids = len(test_product_dict)\n",
    "\n",
    "        dense_matrix = np.zeros(shape=(num_user_ids, num_product_ids), dtype=np.float32)\n",
    "\n",
    "        with open(filename, 'r') as train_file:\n",
    "            matrix_reader = csv.reader(train_file, delimiter=',')\n",
    "            next(matrix_reader, None)\n",
    "            for row in matrix_reader:\n",
    "                dense_matrix[user_dict[row[0]], product_dict[row[1]]] = float(row[2])\n",
    "\n",
    "        return dense_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a matrix with new products on the x axis...\n"
     ]
    }
   ],
   "source": [
    "merged_matrix_product_rows = merged_mtx_products('reviews.training.csv', user_dict, test_product_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_matrix_product_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_matrix_product_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(merged_matrix_product_rows[-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merged_mtx_users(filename, product_dict, test_user_dict):\n",
    "\n",
    "        print('Creating a matrix with new users on the x axis...')\n",
    "\n",
    "        num_product_ids = len(product_dict)\n",
    "        num_user_ids = len(test_user_dict)\n",
    "\n",
    "        dense_matrix = np.zeros(shape=(num_product_ids, num_user_ids), dtype=np.float32)\n",
    "\n",
    "        with open(filename, 'r') as train_file:\n",
    "            matrix_reader = csv.reader(train_file, delimiter=',')\n",
    "            next(matrix_reader, None)\n",
    "            for row in matrix_reader:\n",
    "                dense_matrix[product_dict[row[1]], user_dict[row[0]]] = float(row[2])\n",
    "\n",
    "        return dense_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a matrix with new users on the x axis...\n"
     ]
    }
   ],
   "source": [
    "merged_matrix_user_rows = merged_mtx_users('reviews.training.csv', product_dict, test_user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training_matrix_transposed = training_matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# merged_matrix_user_rows[:training_matrix_transposed.shape[0],\n",
    "#                         :training_matrix_transposed.shape[1]] = training_matrix_transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50050, 123960)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_matrix_user_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 5., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 5., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_matrix_user_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merged_matrix_product_rows = merged_mtx('reviews.test.unlabeled.shortened.csv', 'reviews.test.shortened.csv', test_user_dict,\n",
    "#                            test_product_dict, user_dict, product_dict, 1, 2, 0, 1)\n",
    "# merged_matrix_product_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merged_matrix_user_rows = merged_mtx('reviews.test.unlabeled.shortened.csv', 'reviews.test.shortened.csv', test_product_dict,\n",
    "#                            test_user_dict, product_dict, user_dict, 2, 1, 1, 0)\n",
    "\n",
    "# merged_matrix_user_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_merged_matrix(matrix):\n",
    "\n",
    "    print('Calculating ratings mean...')\n",
    "    matrix_mean = np.mean(matrix, axis=1)\n",
    "    matrix_row_mean = np.true_divide(matrix.sum(1), (matrix != 0).sum(1))\n",
    "    matrix_row_mean = np.nan_to_num(matrix_row_mean)\n",
    "    print('Matrix row mean: ')\n",
    "    print(matrix_row_mean[0])\n",
    "    \n",
    "    matrix_column_mean = np.true_divide(matrix.sum(0), (matrix != 0).sum(0))\n",
    "    matrix_column_mean = np.nan_to_num(matrix_column_mean)\n",
    "    print('matrix column mean: ')\n",
    "    print(matrix_column_mean[951])\n",
    "\n",
    "    matrix_mean_test = np.mean(matrix[matrix > 0])\n",
    "    print(matrix_mean_test)\n",
    "    matrix_mean = matrix.sum(1)/(matrix!=0).sum(1).astype(float)\n",
    "\n",
    "    # global_mean = np.mean(matrix)\n",
    "    # global_mean = np.true_divide(matrix.sum(), (matrix != 0 ).sum())\n",
    "    # print('Global mean: ')\n",
    "    # print(global_mean)\n",
    "\n",
    "    print('Normalizing the data...')\n",
    "    normalized_matrix = matrix - matrix_row_mean.reshape(-1, 1)\n",
    "    print('Normalized matrix: ')\n",
    "    print(normalized_matrix)\n",
    "\n",
    "    print('Test normalized mean value: ')\n",
    "    print(matrix_row_mean[0])\n",
    "    \n",
    "    print('Test column value: ')\n",
    "    print(matrix_column_mean[951])\n",
    "\n",
    "    print('Fill nan with 0')\n",
    "    normalized_matrix = np.nan_to_num(normalized_matrix)\n",
    "    print(normalized_matrix)\n",
    "\n",
    "    return normalized_matrix, matrix_row_mean, matrix_column_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_matrix_product_rows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b597f5a2a223>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnormalized_matrix_products\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix_row_mean_products\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix_column_mean_products\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_merged_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_matrix_product_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'merged_matrix_product_rows' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "normalized_matrix_products, matrix_row_mean_products, matrix_column_mean_products = normalize_merged_matrix(merged_matrix_product_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "normalized_matrix_users, matrix_row_mean_users, matrix_column_mean_users, global_mean = normalize_merged_matrix(merged_matrix_user_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_svd_from_demeaned(urm_demeaned):\n",
    "\n",
    "    print('Computing svd from de-meaned matrix...')\n",
    "\n",
    "    U, sigma, Vt = svds(urm_demeaned, k = 100)\n",
    "    S = np.diag(sigma)\n",
    "\n",
    "    return U, S, Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "U_products, S_products, Vt_products = compute_svd_from_demeaned(normalized_matrix_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "U_users, S_users, Vt_users = compute_svd_from_demeaned(normalized_matrix_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalized_matrix_products.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.dot(np.dot(U_products, S_products), Vt_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "U_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Vt_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalized_matrix_users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.dot(np.dot(U_users, S_users), Vt_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "U_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Vt_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reconstruct_demeaned_matrix(test_file, prediction_file, test_user_dict, test_product_dict,\n",
    "                                U_products, S_products, Vt_products, U_users, S_users, Vt_users,\n",
    "                                matrix_row_mean_products, matrix_row_mean_users):\n",
    "\n",
    "    print('Reconstructing matrix and making predictions...')\n",
    "    \n",
    "#     print(len(test_user_dict))\n",
    "#     print(len(test_product_dict))\n",
    "    \n",
    "    right_term_products = np.dot(S_products, Vt_products)\n",
    "    right_term_users = np.dot(S_users, Vt_users)\n",
    "\n",
    "    with open(test_file, 'r') as test_file:\n",
    "        test_reader = csv.reader(test_file, delimiter=',')\n",
    "        next(test_reader, None)\n",
    "        with open(prediction_file, 'w') as outfile:\n",
    "            outfile_reader = csv.writer(outfile, delimiter=',')\n",
    "            outfile_reader.writerow(['datapointID', 'overall'])\n",
    "\n",
    "            for row in test_reader:\n",
    "\n",
    "                try: \n",
    "                    # Query by user.\n",
    "                    user_query = np.dot(right_term_products.T, U_products[test_user_dict[row[0]], :].T)\n",
    "                    prediction = -user_query[test_product_dict[row[1]]]\n",
    "                    outfile_reader.writerow([row[0], prediction])\n",
    "#                     print('Query by USER')\n",
    "#                     print(row[1])\n",
    "#                     print(prediction)\n",
    "                except:\n",
    "                    try:\n",
    "                        # Query by product.\n",
    "                        product_query = np.dot(right_term_users.T, U_users[test_product_dict[row[1]], :].T)\n",
    "                        prediction = -product_query[test_user_dict[row[0]]]\n",
    "                        outfile_reader.writerow([row[0], prediction])\n",
    "#                         print('Query by PRODUCT')\n",
    "#                         print(row[1])\n",
    "#                         print(prediction)\n",
    "                    except:\n",
    "                        # If no matching users or products are found, make prediction based on global mean.\n",
    "                        prediction = global_mean\n",
    "                        outfile_reader.writerow([row[0], prediction])\n",
    "#                         print('No matching query: GLOBAL MEAN')\n",
    "#                         print(row[1])\n",
    "#                         print(prediction)\n",
    "\n",
    "    print('Done.')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_ratings = reconstruct_demeaned_matrix('reviews.test.unlabeled.csv', 'reviews.test.labeled.csv',\n",
    "                                                test_user_dict, test_product_dict,\n",
    "                                                U_products, S_products, Vt_products, U_users, S_users, Vt_users, \n",
    "                                                matrix_row_mean_products, matrix_row_mean_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
