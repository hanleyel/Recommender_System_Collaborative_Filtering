{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import gzip\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import normalize\n",
    "import csv\n",
    "from sparsesvd import sparsesvd\n",
    "import math\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "from scipy.sparse.linalg import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unzip_json(filename):\n",
    "    print('Unzipping json file...')\n",
    "    unzipped_data = pd.read_json(gzip.open(filename))\n",
    "    return unzipped_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and write json data to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output json training data as a Pandas dataframe.\n",
    "def json_to_df(file_name):\n",
    "\n",
    "    print('Converting json file to dataframe...')\n",
    "\n",
    "    try:\n",
    "        training_data = pd.read_json(file_name, lines=True)\n",
    "        return training_data\n",
    "    except:\n",
    "        print('Please try another file name.')\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "# Convert Pandas dataframe to csv file for storage purposes.\n",
    "# NOTE: Don't run this with the actual training data. This was just for saving a small version of the file for time\n",
    "# saving purposes while I was setting up my dataframe and matrices.\n",
    "def convert_to_csv(dataframe, desired_filename):\n",
    "\n",
    "    print('Converting dataframe to csv: ' + desired_filename + '...')\n",
    "\n",
    "    try:\n",
    "        return dataframe.to_csv(desired_filename, index=False)\n",
    "    except:\n",
    "        print('Please try another dataframe or file name.')\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A34DNO6UAH67Z0</td>\n",
       "      <td>B000CDSS22</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3APW42N5MRVWT</td>\n",
       "      <td>6305186774</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A20D9VGCF3P13L</td>\n",
       "      <td>B004LWZW24</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A82LIVYSX6WZ9</td>\n",
       "      <td>B00001U0DM</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3LRKDF5WU4ZDO</td>\n",
       "      <td>B00005JOZI</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  overall\n",
       "0  A34DNO6UAH67Z0  B000CDSS22        5\n",
       "1  A3APW42N5MRVWT  6305186774        2\n",
       "2  A20D9VGCF3P13L  B004LWZW24        5\n",
       "3   A82LIVYSX6WZ9  B00001U0DM        3\n",
       "4  A3LRKDF5WU4ZDO  B00005JOZI        3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = pd.read_csv('reviews.dev.csv')\n",
    "shortened_reviews = reviews_df.head(1000)\n",
    "shortened_reviews.to_csv('reviews.test.shortened.csv', index = False)\n",
    "shortened_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and store CSV data as sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns dictionaries with unique users and products as keys and unique ints as values.\n",
    "def create_user_product_dicts(filename):\n",
    "\n",
    "    print('Creating dictionaries from CSV for unique users and products...')\n",
    "\n",
    "    user_dict = {}\n",
    "    product_dict = {}\n",
    "    user_count = 0\n",
    "    product_count = 0\n",
    "\n",
    "    with open(filename, 'r') as train_file:\n",
    "        file_reader=csv.reader(train_file, delimiter=',')\n",
    "        next(file_reader, None)\n",
    "\n",
    "        for row in file_reader:\n",
    "            if row[0] not in user_dict:\n",
    "                user_dict[row[0]] = user_count\n",
    "                user_count += 1\n",
    "            if row[1] not in product_dict:\n",
    "                product_dict[row[1]] = product_count\n",
    "                product_count += 1\n",
    "\n",
    "    return user_dict, product_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dictionaries from CSV for unique users and products...\n"
     ]
    }
   ],
   "source": [
    "user_dict, product_dict = create_user_product_dicts('reviews.test.shortened.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve test users and products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Outputs dictionaries with unique test users and test products.\n",
    "# def get_test_users_products(filename, training_user_dict, training_product_dict):\n",
    "\n",
    "#     print('Importing test users and products...')\n",
    "\n",
    "#     test_user_count = len(training_user_dict)\n",
    "#     test_product_count = len(training_product_dict)\n",
    "#     # test_user_count = 0\n",
    "#     # test_product_count = 0\n",
    "#     test_user_dict = {}\n",
    "#     test_product_dict = {}\n",
    "\n",
    "#     with open(filename, 'r') as test_file:\n",
    "#         test_reader = csv.reader(test_file, delimiter=',')\n",
    "#         next(test_reader, None)\n",
    "\n",
    "#         for row in test_reader:\n",
    "#             # Add unique users to test_user dictionary.\n",
    "#             if row[1] in training_user_dict and row[1 not in test_user_dict]:\n",
    "#                 test_user_dict[row[1]] = training_user_dict[row[1]]\n",
    "#             elif row[1] not in test_user_dict:\n",
    "#                 test_user_count += 1\n",
    "#                 test_user_dict[row[1]] = test_user_count\n",
    "#             # Add unique products to test_product dictionary.\n",
    "#             if row[2] in training_product_dict and row[2 not in test_product_dict]:\n",
    "#                 test_product_dict[row[2]] = training_product_dict[row[2]]\n",
    "#             elif row[2] not in test_product_dict:\n",
    "#                 test_product_count += 1\n",
    "#                 test_product_dict[row[2]] = test_product_count\n",
    "\n",
    "#     return test_user_dict, test_product_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing test users and products...\n"
     ]
    }
   ],
   "source": [
    "# test_user_dict, test_product_dict = get_test_users_products('reviews.test.shortened.csv', user_dict, product_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A34DNO6UAH67Z0</td>\n",
       "      <td>B000CDSS22</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3APW42N5MRVWT</td>\n",
       "      <td>6305186774</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A20D9VGCF3P13L</td>\n",
       "      <td>B004LWZW24</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A82LIVYSX6WZ9</td>\n",
       "      <td>B00001U0DM</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3LRKDF5WU4ZDO</td>\n",
       "      <td>B00005JOZI</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  overall\n",
       "0  A34DNO6UAH67Z0  B000CDSS22        5\n",
       "1  A3APW42N5MRVWT  6305186774        2\n",
       "2  A20D9VGCF3P13L  B004LWZW24        5\n",
       "3   A82LIVYSX6WZ9  B00001U0DM        3\n",
       "4  A3LRKDF5WU4ZDO  B00005JOZI        3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv('reviews.test.shortened.csv')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dense matrix, normalize matrix, sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def demean_to_dense_to_sparse(filename, user_dict, product_dict):\n",
    "    \n",
    "    \n",
    "    print('Creating a first dense matrix from rating data...')\n",
    "    num_user_ids = len(user_dict)\n",
    "    num_product_ids = len(product_dict)\n",
    "    urm = np.zeros(shape=(num_user_ids, num_product_ids), dtype=np.float32)\n",
    "\n",
    "    with open(filename, 'r') as train_file:\n",
    "        urmReader = csv.reader(train_file, delimiter=',')\n",
    "        next(urmReader, None)\n",
    "        for row in urmReader:\n",
    "            urm[user_dict[row[0]], product_dict[row[1]]] = float(row[2])\n",
    "            \n",
    "            \n",
    "    print('Normalizing the data...')\n",
    "    \n",
    "    urm_mean = np.mean(urm, axis = 1)\n",
    "    urm_demeaned = urm - urm_mean.reshape(-1, 1)\n",
    "\n",
    "    \n",
    "    print('Creating a sparse CSC matrix from dense rating matrix data...')\n",
    "    urm_sparse_csc = scipy.sparse.csc_matrix(urm_demeaned, dtype=np.float32)\n",
    "\n",
    "    return urm_sparse_csc, num_user_ids, num_product_ids, urm, urm_demeaned, urm_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a first dense matrix from rating data...\n",
      "Normalizing the data...\n",
      "Creating a sparse CSC matrix from dense rating matrix data...\n"
     ]
    }
   ],
   "source": [
    "sparse_matrix, num_user_ids, num_product_ids, urm, urm_demeaned, urm_mean = demean_to_dense_to_sparse('reviews.test.shortened.csv', user_dict, product_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 2., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 5., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 2., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 5., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(969, 944)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement SVD from dense matrix with svds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "U, sigma, Vt = svds(urm, k = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(969, 100)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = np.diag(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 944)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruct matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.6761841e-02, -1.2458201e-11, -3.1800680e-02, ...,\n",
       "        -2.8599407e-09,  2.8444532e-02, -3.0775258e-09],\n",
       "       [-4.9832785e-12,  1.1377195e-19, -1.8118337e-12, ...,\n",
       "         9.5448404e-18, -1.5936181e-11, -1.1105061e-11],\n",
       "       [-3.1800680e-02, -4.5295885e-12,  4.8076892e-01, ...,\n",
       "        -8.1930054e-09,  6.6875592e-03, -2.8617521e-08],\n",
       "       ...,\n",
       "       [-1.5789248e-02,  1.6943546e-11,  5.0108746e-02, ...,\n",
       "         7.8771141e-09,  2.0622434e-03, -1.1268533e-09],\n",
       "       [-1.1439764e-09,  9.5448421e-18, -3.2772023e-09, ...,\n",
       "         1.1586716e-14, -1.0339353e-08,  3.3252934e-09],\n",
       "       [ 2.8444530e-02, -3.9840447e-11,  6.6875592e-03, ...,\n",
       "        -2.5848387e-08,  2.8322119e-01,  1.2837303e-08]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.dot(U, s), Vt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De-mean/normalize the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "urm_mean = np.mean(urm, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0052966103"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urm_mean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "urm_demeaned = urm - urm_mean.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.9947033e+00, -5.2966103e-03, -5.2966103e-03, ...,\n",
       "        -5.2966103e-03, -5.2966103e-03, -5.2966103e-03],\n",
       "       [-2.1186441e-03,  1.9978814e+00, -2.1186441e-03, ...,\n",
       "        -2.1186441e-03, -2.1186441e-03, -2.1186441e-03],\n",
       "       [-5.2966103e-03, -5.2966103e-03,  4.9947033e+00, ...,\n",
       "        -5.2966103e-03, -5.2966103e-03, -5.2966103e-03],\n",
       "       ...,\n",
       "       [-5.2966103e-03, -5.2966103e-03, -5.2966103e-03, ...,\n",
       "        -5.2966103e-03, -5.2966103e-03, -5.2966103e-03],\n",
       "       [-2.1186441e-03, -2.1186441e-03, -2.1186441e-03, ...,\n",
       "         1.9978814e+00, -2.1186441e-03, -2.1186441e-03],\n",
       "       [-5.2966103e-03, -5.2966103e-03, -5.2966103e-03, ...,\n",
       "        -5.2966103e-03,  4.9947033e+00, -5.2966103e-03]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urm_demeaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "U, sigma, Vt = svds(urm_demeaned, k = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S = np.diag(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_ratings = (np.dot(np.dot(U, S), Vt) + urm_mean.reshape(-1, 1)*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.2972198, 5.296897 , 5.2972198, ..., 5.296897 , 5.2972198,\n",
       "        5.2893863],\n",
       "       [2.1187587, 2.118701 , 2.1187587, ..., 2.118701 , 2.1187587,\n",
       "        2.117465 ],\n",
       "       [5.2972198, 5.296897 , 5.2972198, ..., 5.296897 , 5.2972198,\n",
       "        5.2893863],\n",
       "       ...,\n",
       "       [5.2972198, 5.296897 , 5.2972198, ..., 5.296897 , 5.2972198,\n",
       "        5.2893863],\n",
       "       [2.1187587, 2.118701 , 2.1187587, ..., 2.118701 , 2.1187587,\n",
       "        2.117465 ],\n",
       "       [5.2972198, 5.296897 , 5.2972198, ..., 5.296897 , 5.2972198,\n",
       "        5.2893863]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.118701], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings[[user_dict['A3APW42N5MRVWT']],[product_dict['6305186774']]] # Should be 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.1781025], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings[[user_dict['A3LRKDF5WU4ZDO']],[product_dict['B00005JOZI']]] # Should be 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.1780736], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings[[user_dict['A3LRKDF5WU4ZDO']],[product_dict['6305186774']]] # Should be ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying the SVD matrix again with de-meaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "U, S, Vt = computeSVD(sparse_matrix, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make ratings predictions from SVD matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recompose_matrix(U, S, Vt, user_dict, product_dict):\n",
    "\n",
    "    rightTerm = np.dot(S, Vt)\n",
    "\n",
    "    print('Right Term')\n",
    "    print(rightTerm.shape)\n",
    "    print(rightTerm)\n",
    "\n",
    "    estimated_ratings = np.zeros(shape=(len(user_dict), len(product_dict)), dtype=np.float16)\n",
    "\n",
    "    with open('reviews.training.csv', 'r') as test_file:\n",
    "        test_reader = csv.reader(test_file, delimiter=',')\n",
    "        next(test_reader, None)\n",
    "        with open('reviews.test.labeled.csv', 'w') as outfile:\n",
    "            outfile_reader = csv.writer(outfile, delimiter=',')\n",
    "            outfile_reader.writerow(['userID', 'actual overall', 'predicted'])\n",
    "\n",
    "            for row in test_reader:\n",
    "                pass\n",
    "\n",
    "                print('U queried shape')\n",
    "                u_queried = U[:, user_dict[row[0]]]\n",
    "                # print(u_queried.shape)\n",
    "                print(u_queried)\n",
    "                #\n",
    "                print('Right term queried shape')\n",
    "                rt_queried = rightTerm[:, product_dict[row[1]]]\n",
    "                # print(rt_queried.shape)\n",
    "                print(rt_queried)\n",
    "                #\n",
    "                print('Product of u queried by rt queried')\n",
    "                prod = np.dot(u_queried, rt_queried)\n",
    "                print(prod.shape)\n",
    "                print(prod)\n",
    "\n",
    "                # print('Estimated ratings')\n",
    "                # estimated_ratings[:, user_dict[row[0]]] = prod.todense()\n",
    "                # print(estimated_ratings)\n",
    "\n",
    "                # estimated_ratings[user_dict[row[0]], :] = prod.todense()\n",
    "                # predicted_rating = (estimated_ratings[user_dict[row[0]], product_dict[row[1]]])\n",
    "                outfile_reader.writerow([row[0], row[2], prod])\n",
    "\n",
    "    return estimated_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Term\n",
      "(3, 944)\n",
      "[[ 1.95178935e-20 -1.79320799e-17 -3.62921679e-17 ...  7.25561708e-17\n",
      "   1.26387935e-16  1.14096283e-16]\n",
      " [-1.75554369e-20  2.02293626e-16  3.78484008e-17 ... -7.97219254e-16\n",
      "  -1.31921309e-16 -1.34773945e-15]\n",
      " [ 3.28741732e-20 -1.41293686e-17 -4.56704885e-16 ... -3.69167201e-17\n",
      "   2.10447054e-16 -3.42716586e-16]]\n",
      "U queried shape\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'AMFIPCYDYWGVT'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-216-cc5365d9cb8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimated_ratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecompose_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproduct_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-215-411ed03a8db1>\u001b[0m in \u001b[0;36mrecompose_matrix\u001b[0;34m(U, S, Vt, user_dict, product_dict)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'U queried shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mu_queried\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0;31m# print(u_queried.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_queried\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'AMFIPCYDYWGVT'"
     ]
    }
   ],
   "source": [
    "estimated_ratings = recompose_matrix(U, S, Vt, user_dict, product_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
